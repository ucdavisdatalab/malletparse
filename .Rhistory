library("textprocessingDSI")
rcpp_join("~/test/", "~/joined.txt", 1)
pwd()
getwd9)
getwd()
rcpp_join("~/test/", "joined.txt", 1)
rcpp_join("./test/", "joined.txt", 1)
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
library("textprocessingDSI")
files = rcpp_join("/data/Water-Management/english-texts/", "/data/Water-Management/joined.txt", 1)
knitr::opts_chunk$set(
collapse = TRUE,
eval = FALSE
comment = "#>"
knitr::opts_chunk$set(
collapse = TRUE,
eval = FALSE
comment = "#>"
knitr::opts_chunk$set(
collapse = TRUE,
eval = FALSE,
comment = "#>"
)
mylist = create_tt(x)
create_tt = function(x)
{
mylist = lapply(x, order)
return (mylist)
}
x = matrix(1:9, nrow = 3, ncol = 3)
mylist = create_tt(x)
mylist
x
mylist[[1]]
create_tt = function(x)
{
mylist = apply(x, order)
return (mylist)
}
x = matrix(1:9, nrow = 3, ncol = 3)
mylist = create_tt(x)
x = matrix(1:9, nrow = 3, ncol = 3)
x2 = apply(x, order)
x2 = apply(x, 1, order)
x2
x
x2 = apply(x, 1, sort)
x2
x
x2 = apply(x, 1, order)
x23
x2
x
order(x[1,])
order(x[2,])
source('~/test.R')
x
2x2
x2
x2 = apply(x, 2, order)
x2
x2 = apply(x, 1, order)
x2
x2[1]
x2[1,]
x2 = t(apply(x, 1, order))
x2
x
x =matrix(runif(5*2), ncol=5)
x2 = t(apply(x, 1, order))
x
x2
?order
x2 = t(apply(x, 1, order, decreasing=TRUE))
x2
x
source('~/test.R')
source('~/test.R')
source('~/test.R')
source('~/test.R')
source('~/test.R')
source('~/test.R')
source('~/test.R')
source('~/test.R')
scores
scores = x[indsorted]
source('~/test.R')
source('~/test.R')
scores
scores
source('~/test.R')
source('~/test.R')
library(JSONIO)
source('~/test.R')
install.packages("JSONIO")
library(jsonlite)
a = c(1, 2,3,4,5,56)
a
test = toJSON(a)
test
source('~/test.R')
vocab
class(vocab)
toJSON(vocab)
vocab[1,2,3]
vocab[,1,2,3]
{
indsorted = t(apply(x, 1, order, decreasing=TRUE))
for (i in 1:nrow(indsorted))
{
inds = indsorted[i,]
scores = (x[i,][inds][1:5])
terms = (vocab[inds][1:5])
jsscores = toJSON(scores)
jsterms = toJSON(terms)
name = paste("'name':", i,sep="")
rscores = paste("'scores':",jsscores,sep="")
rterms = paste("'terms':", jsterms,sep="")
res = paste('{', name, ',', rscores, ',', rterms,'}',sep="")
print(res)
}
create_tt = function(x, vocab)
{
indsorted = t(apply(x, 1, order, decreasing=TRUE))
for (i in 1:nrow(indsorted))
{
inds = indsorted[i,]
scores = (x[i,][inds][1:5])
terms = (vocab[inds][1:5])
jsscores = toJSON(scores)
jsterms = toJSON(terms)
name = paste("'name':", i,sep="")
rscores = paste("'scores':",jsscores,sep="")
rterms = paste("'terms':", jsterms,sep="")
res = paste('{', name, ',', rscores, ',', rterms,'}',sep="")
print(res)
}
}
vocab = c("one", "two", "three", "four", "five", "six")
x =matrix(runif(5*2), ncol=5)
scores = create_tt(x, vocab)
create_tt = function(x, vocab)
{
indsorted = t(apply(x, 1, order, decreasing=TRUE))
for (i in 1:nrow(indsorted))
{
inds = indsorted[i,]
scores = (x[i,][inds][1:5])
terms = (vocab[inds][1:5])
jsscores = toJSON(scores)
jsterms = toJSON(terms)
name = paste("'name':", i,sep="")
rscores = paste("'scores':",jsscores,sep="")
rterms = paste("'terms':", jsterms,sep="")
res = paste('{', name, ',', rscores, ',', rterms,'}',sep="")
print(res)
}
}
vocab = c("one", "two", "three", "four", "five", "six")
x =matrix(runif(5*2), ncol=5)
scores = create_tt(x, vocab)
source('~/test.R')
)
source('~/test.R')
source('~/test.R')
source('~/test.R')
source('~/test.R')
?paste
source('~/test.R')
source('~/test.R')
source('~/test.R')
source('~/test.R')
source('~/test.R')
source('~/test.R')
source('~/test.R')
source('~/test.R')
source('~/test.R')
source('~/test.R')
source('~/test.R')
source('~/test.R')
source('~/test.R')
source('~/test.R')
res
source('~/test.R')
res
cat(res)
source('~/test.R')
cat(res)
source('~/test.R')
cat(res)
source('~/test.R')
cat(res)
source('~/test.R')
cat(res)
x
source('~/test.R')
cat(res2)
source('~/test.R')
cat(res)
cat(res2)
source('~/test.R')
cat(res2)
source('~/test.R')
source('~/test.R')
cat(res)
cat(res2)
cat(res3)
source('~/test.R')
cat(res3)
knitr::opts_chunk$set(echo = TRUE)
library(ldaviewerDSI)
library(ldaviewerDSI)
?create_viewer
source('~/procrustes.R')
source('~/procrustes.R')
install.packages("igraph")
source('~/procrustes.R')
source('~/procrustes.R')
data.plot
RSS
procrustes.results$RSS
install.packages("rvest")
library("rvest")
?read_html
source('~/temp.R')
source
source
source
source('~/temp.R')
h2tags
html_text(source)
full = html_text(source)
clean = gsub("\n", "", full)
clean
source('~/temp.R')
h2text
source('~/temp.R')
tags
text
# get the values for those nodes
text = html_text(tags)
text
source('~/temp.R')
text
source('~/temp.R')
tags
source('~/temp.R')
lis
# get the values for those nodes
text = html_text(lis)
text
clean_text = gsub ("[[:punct:]]", "", text)
clean_text
source('~/temp.R')
clean_text
source('~/temp.R')
clean_text
clean_text = gsub (c("[[:punct:]]", "\n", "\t"), " ", text)
class(text)
length(text)
str(character)
str(text)
clean_function = function (x)
{
x = gsub ("[[:punct:]]", "", x)
x = gsub ("\n", "", x)
x = gsub ("\t", " ", x)
x = tolower(x)
return (x)
}
clean_function(text[1])
clean_text = lapply (text, clean_function)
clean_text
library(malletparseDSI)
help("malletparseDSI-package")
?rcpp_parse_doc_topics
setwd("~/programs/r-packages/malletparse/malletparseDSI")
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
library(malletparseDSI)
# use this to save to file: statelist = rcpp_parse_topic_state("../data/state-file.gz", dtflag=0, dtfile="../data/doc-topics.gz")
statefile = system.file("extdata", "state-file.gz", package="malletparseDSI")
statelist = rcpp_parse_topic_state(statefile, dtflag=0)
str(statelist)
dtfile = system.file("extdata", "doc-topics.dat", package="malletparseDSI")
dtlist = rcpp_parse_doc_topics(dtfile, 20, doc_lens = statelist$doc_lens) #second arg is number of documents to save for each topic
str(dtlist)
dtfile2 = system.file("extdata", "doc-topics.gz", package="malletparseDSI")
dtlist2 = rcpp_parse_doc_topics(dtfile2, 20, doc_lens = statelist$doc_lens)
dtfile2 = system.file("extdata", "doc-topics.gz", package="malletparseDSI")
dtlist2 = rcpp_parse_doc_topics(dtfile2, 20, doc_lens = statelist$doc_lens)
str(dtlist2)
wtcfile = system.file("extdata", "word-topic-counts.dat", package="malletparseDSI")
topic_terms = rcpp_parse_word_topic_counts(wtcfile, 10) # third arg is ntopics
print(dim(topic_terms))
print(head(topic_terms[,1:5]))
wwfile = system.file("extdata", "word-weights.dat", package="malletparseDSI")
topic_terms = rcpp_parse_topic_word_weights(wwfile)
print(dim(topic_terms))
print(head(topic_terms[,1:5]))
tt_dist = t(apply(topic_terms, 1, function(x) x/sum(x))) ## convert topic terms count matrix to distribution
json = no_doc_topics_createJSON(
phi = tt_dist,
topic.frequency = dtlist$topic_frequencies,
vocab = statelist$terms,
term.frequency = statelist$term_freqs)
library(LDAvis)
LDAvis::serVis(json)
